README file for Programming Assignment 1 (Java edition)
=======================================================

Your directory should now contain the following files:

 Makefile
 README
 cool.lex
 test.cl
 AbstractSymbol.java  -> [course dir]/src/PA1J/AbstractSymbol.java
 BoolConst.java       -> [course dir]/src/PA1J/BoolConst.java
 Flags.java           -> [course dir]/src/PA1J/Flags.java
 IdSymbol.java        -> [course dir]/src/PA1J/IdSymbol.java
 IdTable.java         -> [course dir]/src/PA1J/IdTable.java
 IntSymbol.java       -> [course dir]/src/PA1J/IntSymbol.java
 IntTable.java        -> [course dir]/src/PA1J/IntTable.java
 Lexer.java           -> [course dir]/src/PA1J/Lexer.java
 AbstractTable.java   -> [course dir]/src/PA1J/AbstractTable.java
 StringSymbol.java    -> [course dir]/src/PA1J/StringSymbol.java
 StringTable.java     -> [course dir]/src/PA1J/StringTable.java
 Utilities.java       -> [course dir]/src/PA1J/Utilities.java
 TokenConstants.java  -> [course dir]/src/PA1J/TokenConstants.java
 *.java		      other generated files

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.lex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	TokenConstants.java contains constant definitions that are used by
	almost all parts of the compiler. DO NOT MODIFY.

	*Table.java and *Symbol.java contain string table data
	structures.  DO NOT MODIFY.

	Utilities.java contains various support functions used by the
	main lexer driver (Lexer.java).  DO NOT MODIFY.

	Lexer.java contains the main method which will call your lexer
	and print out the tokens that it returns.  DO NOT MODIFY.

        CoolLexer.java is the scanner generated by jlex from cool.lex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run jlex.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% make submit

	Running "submit" will collect the files cool.lex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.


	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA1J
-----------------

===================
>>>>> User ID <<<<<
===================
user: yh3483
user: borui

=======================================
>>>>> Regular Expressions Defined <<<<<
=======================================
INTEGER = [0-9]+	
VTRUE = t(R|r)(U|u)(E|e)
VFALSE = f(A|a)(L|l)(S|s)(E|e)
NEWLINE = \n
WHITESPACES = [\b\t\f\r ]+
CLASSNAME = ([A-Z][A-Za-z0-9_]*)|(SELF_TYPE)
OBJECTNAME = [a-z][A-Za-z0-9_]*	

========================
>>>>> Lexer States <<<<<
========================

1. YYINITIAL: the initial state, matches
	- keywords
	- operators
	- identifiers
	- integer/boolean constants
	- beginning of multiline/inline comments or string constants
	- whitespaces

2. COMMENT_MULTI: inside a multi-line comment, matches
	- beginning of multline comments '(' '*'
	- ending of multiline comments '*' ')'
	- newline character '\n'

3. COMMENT_INLINE: inside an inline comment, matches
	- newline character '\n'
		
4. STRING: inside a string constant, matches
	- ending of string constant '"'
	- multiline string '\'
	- null character '\0'
	- escaped characters (any characters preceeded by '\')
	- regular characters
		
5. ILLEGAL_STRING: inside an illegal string constant, matches
	- ending of string constant '"'
	- newline character '\n'


===========================
>>>>> Global Variable <<<<<
===========================
1. StringBuffer string_buf: 
	- cleared when transition from YYINITIAL to STRING
	- append characters to this buffer while in STRING state
	
2. int comment_level: 
	- set to 1 when transition from YYINITIAL to COMMENT_MULTI
	- increment when matching '(''*' in COMMENT_MULTI state
	- decrement when matching '*'')' in COMMENT_MULTI state
	
3. int curr_lineno: 
	- set to 1 at the beginning of lexer execution
	- increment when matching '\n' in any state

=============================
>>>>> State Transitions <<<<<
=============================
1. YYINITIAL -> STRING: 
	when matching '"'			
	
2. YYINITIAL -> COMMENT_MULTI: 
	when matching '(''*'
	
3. YYINITIAL -> COMMENT_INLINE: 
	when matching '-''-'
	
4. STRING -> YYINITIAL: 
	when matching '"', or
	when EOF encountered (transition before returning ERROR)
	
5. STRING -> ILLEGAL_STRING: 
	when matching '\0', or 
	when string_buf.length() >= MAX_STR_CONST
	
6. ILLEGAL_STRING -> YYINITIAL:
	when matching '\0', or
	when matching '\n'
	
7. COMMENT_MULTI -> YYINITIAL:
	when matching '*'')' and comment_level == 1, or
	when EOF encountered (transition before returning ERROR)
	
8. COMMENT_INLINE -> YYINITIAL:
	when matching '\n'

=========================
>>>>> EOF Condition <<<<<
=========================
- YYINITIAL, COMMENT_INLINE: normal condition, return EOF
- STRING, COMMENT_MULTI: error condition, return ERROR
- ILLEGAL_STRING: error already returned, so return EOF


=============================
>>>>> Method of Testing <<<<<
=============================

Our method of testing involves creating many test files containing COOL 
sematics, running our lexer implementation with the test files, and comparing
the output with the provided reference solution. This automation is carried 
out by a python script (test.py). 

We used the following test inputs (under the tests directory):
- test.cl: the given test case
- exp.cl: over 200 hand-crafted, single-line inputs over the numbers, alphabet, 
	strings, whitespaces, Booleans, identifier, comments and keywords; 
	containing all the corner circumstances we could think of regarding both 
	correct and incorrect syntax and formatting according to the assignmentâ€™s 
	requirements.
- exp_gen.cl: 1000 randomly generated lines by a ruby script (test_gen.rb), 
	each line consisted of 20 inputs from exp.cl; testing for multiple tokens 
	in a single line
- null.cl: inputs with null characters in identifier, string constant, and 
	comments; generated by a python script (testgen_null_eof.py)
- eof_comment.cl
- eof_inline.cl
- eof_string.cl: inputs with eof characters terminating string constant and 
	comments; generated by a python script (testgen_null_eof.py)

The above seven test input files covers all the cases we can conceive of. 
Our implementation having passed all of them, so we are quite confident that 
our implementation of the lexer is correct to the assignment specification.
